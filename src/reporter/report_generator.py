import re
import json
import logging
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent.parent
LOG_DIR = PROJECT_ROOT / "logs"
REPORT_DIR = PROJECT_ROOT / "docs" / "08.Report"

LOG_FILE_FORMAT = "redarrow_{}.log"
SUMMARY_FILE_FORMAT = "summary_{}.json"
REPORT_FILE_FORMAT = "{}_íˆ¬ìê²°ê³¼.md"

# ë¡œê·¸ íŒŒì‹± íŒ¨í„´ (ì‹¤ì œ ê±°ë˜ ì´ë²¤íŠ¸ë§Œ ë§¤ì¹­)
# ë§¤ìˆ˜: "âœ… ë§¤ìˆ˜ ì£¼ë¬¸ ì ‘ìˆ˜ ì„±ê³µ: {ì¢…ëª©ëª…} {ìˆ˜ëŸ‰}ì£¼ @ {ê°€ê²©}ì› (ì£¼ë¬¸ë²ˆí˜¸: {ë²ˆí˜¸})"
BUY_PATTERN = re.compile(
    r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),\d+ - .+ - INFO - "
    r"âœ… ë§¤ìˆ˜ ì£¼ë¬¸ ì ‘ìˆ˜ ì„±ê³µ: (.+?) (\d+)ì£¼ @ ([\d,]+)ì›"
)

# ë§¤ë„: "âœ… ë§¤ë„ ì£¼ë¬¸ ì²´ê²° ì„±ê³µ: {ì¢…ëª©ëª…} {ìˆ˜ëŸ‰}ì£¼ @ {ê°€ê²©}ì› (ì£¼ë¬¸ë²ˆí˜¸: {ë²ˆí˜¸})"
SELL_PATTERN = re.compile(
    r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),\d+ - .+ - INFO - "
    r"âœ… ë§¤ë„ ì£¼ë¬¸ ì²´ê²° ì„±ê³µ: (.+?) (\d+)ì£¼ @ ([\d,]+)ì›"
)

# ì²­ì‚°: "âœ… ì²­ì‚° ì£¼ë¬¸ ì²´ê²° ì„±ê³µ: {ì¢…ëª©ëª…} {ìˆ˜ëŸ‰}ì£¼, ì§„ì…ê°€ {ê°€ê²©}ì›, ì²­ì‚°ê°€ {ê°€ê²©}ì›"
LIQUIDATION_PATTERN = re.compile(
    r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),\d+ - .+ - INFO - "
    r"âœ… ì²­ì‚° ì£¼ë¬¸ ì²´ê²° ì„±ê³µ: (.+?) (\d+)ì£¼, ì§„ì…ê°€ ([\d,]+)ì›, ì²­ì‚°ê°€ ([\d,]+)ì›"
)

# ì†ìµ: "ğŸ’° ì²­ì‚° ì†ìµ: {ê¸ˆì•¡}ì› ({ë¹„ìœ¨}%)"
PNL_PATTERN = re.compile(
    r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),\d+ - .+ - INFO - "
    r"ğŸ’° ì²­ì‚° ì†ìµ: ([\d,.-]+)ì› \(([\d.+-]+)%\)"
)


def setup_reporter():
    """ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    REPORT_DIR.mkdir(parents=True, exist_ok=True)


def parse_summary_file(date_str: str):
    """
    í•´ë‹¹ ë‚ ì§œì˜ ìš”ì•½ JSON íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤.

    Args:
        date_str: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´

    Returns:
        ìš”ì•½ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
    """
    summary_file_path = LOG_DIR / SUMMARY_FILE_FORMAT.format(date_str)
    if not summary_file_path.exists():
        logger.warning(f"ìš”ì•½ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {summary_file_path}")
        return None

    try:
        with open(summary_file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"ìš”ì•½ íŒŒì¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def parse_log_file(date_str: str):
    """
    í•´ë‹¹ ë‚ ì§œì˜ ë¡œê·¸ íŒŒì¼ì—ì„œ ì‹¤ì œ ê±°ë˜ ì´ë²¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        date_str: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´

    Returns:
        (buy_events, sell_events, pnl_events) íŠœí”Œ
        - buy_events: [{'time': str, 'name': str, 'quantity': int, 'price': str}, ...]
        - sell_events: [{'time': str, 'name': str, 'quantity': int, 'price': str, 'type': str}, ...]
        - pnl_events: [{'time': str, 'amount': str, 'percent': str}, ...]
    """
    log_file_path = LOG_DIR / LOG_FILE_FORMAT.format(date_str)
    buy_events = []
    sell_events = []
    pnl_events = []

    if not log_file_path.exists():
        logger.warning(f"ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file_path}")
        return buy_events, sell_events, pnl_events

    with open(log_file_path, "r", encoding="utf-8") as f:
        for line in f:
            # ë§¤ìˆ˜ ì£¼ë¬¸ ì ‘ìˆ˜ ì„±ê³µ
            m = BUY_PATTERN.search(line)
            if m:
                buy_events.append({
                    'time': m.group(1).split(' ')[1],
                    'name': m.group(2),
                    'quantity': int(m.group(3)),
                    'price': m.group(4),
                })
                continue

            # ë§¤ë„ ì£¼ë¬¸ ì²´ê²° ì„±ê³µ
            m = SELL_PATTERN.search(line)
            if m:
                sell_events.append({
                    'time': m.group(1).split(' ')[1],
                    'name': m.group(2),
                    'quantity': int(m.group(3)),
                    'price': m.group(4),
                    'type': 'ë§¤ë„',
                })
                continue

            # ì²­ì‚° ì£¼ë¬¸ ì²´ê²° ì„±ê³µ
            m = LIQUIDATION_PATTERN.search(line)
            if m:
                sell_events.append({
                    'time': m.group(1).split(' ')[1],
                    'name': m.group(2),
                    'quantity': int(m.group(3)),
                    'price': m.group(5),  # ì²­ì‚°ê°€
                    'type': 'ì²­ì‚°',
                    'entry_price': m.group(4),
                })
                continue

            # ì²­ì‚° ì†ìµ
            m = PNL_PATTERN.search(line)
            if m:
                pnl_events.append({
                    'time': m.group(1).split(' ')[1],
                    'amount': m.group(2),
                    'percent': m.group(3),
                })

    return buy_events, sell_events, pnl_events


def generate_report_content(date_str: str, buy_events: list, sell_events: list,
                            pnl_events: list, summary_data: dict) -> str:
    """
    ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ì¼ì¼ ë¦¬í¬íŠ¸ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
        buy_events: ë§¤ìˆ˜ ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        sell_events: ë§¤ë„/ì²­ì‚° ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        pnl_events: ì†ìµ ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        summary_data: ìš”ì•½ JSON ë°ì´í„°

    Returns:
        ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ë¬¸ìì—´
    """
    lines = []
    lines.append(f"# {date_str} íˆ¬ì ê²°ê³¼ ë¦¬í¬íŠ¸\n")
    lines.append("---\n")

    # ë§¤ìˆ˜ ê¸°ë¡
    lines.append("## ë§¤ìˆ˜ ê¸°ë¡\n")
    if buy_events:
        lines.append("| ì‹œê°„ | ì¢…ëª© | ìˆ˜ëŸ‰ | ì£¼ë¬¸ê°€ |")
        lines.append("|------|------|-----:|-------:|")
        for e in buy_events:
            lines.append(f"| {e['time']} | {e['name']} | {e['quantity']}ì£¼ | {e['price']}ì› |")
        lines.append("")
    else:
        lines.append("í•´ë‹¹ì¼ì— ë§¤ìˆ˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\n")

    # ë§¤ë„/ì²­ì‚° ê¸°ë¡
    lines.append("## ë§¤ë„/ì²­ì‚° ê¸°ë¡\n")
    if sell_events:
        lines.append("| ì‹œê°„ | ì¢…ëª© | ìœ í˜• | ìˆ˜ëŸ‰ | ì²´ê²°ê°€ |")
        lines.append("|------|------|------|-----:|-------:|")
        for e in sell_events:
            lines.append(f"| {e['time']} | {e['name']} | {e['type']} | {e['quantity']}ì£¼ | {e['price']}ì› |")
        lines.append("")
    else:
        lines.append("í•´ë‹¹ì¼ì— ë§¤ë„/ì²­ì‚° ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\n")

    # ì†ìµ ê¸°ë¡
    lines.append("## ì†ìµ ê¸°ë¡\n")
    if pnl_events:
        lines.append("| ì‹œê°„ | ì†ìµ | ìˆ˜ìµë¥  |")
        lines.append("|------|-----:|-------:|")
        for e in pnl_events:
            lines.append(f"| {e['time']} | {e['amount']}ì› | {e['percent']}% |")
        lines.append("")
    else:
        lines.append("í•´ë‹¹ì¼ì— ì†ìµ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\n")

    # ì´í‰ ë° ê²°ê³¼
    lines.append("## ì´í‰ ë° ê²°ê³¼\n")
    lines.append(f"- **ë§¤ìˆ˜ ê±´ìˆ˜**: {len(buy_events)}ê±´")
    lines.append(f"- **ë§¤ë„/ì²­ì‚° ê±´ìˆ˜**: {len(sell_events)}ê±´")

    if summary_data:
        pnl = summary_data.get('daily_pnl', 0)
        final_balance = summary_data.get('final_balance', 0)
        lines.append(f"- **ë‹¹ì¼ ì‹¤í˜„ ì†ìµ**: {pnl:,.0f}ì›")
        lines.append(f"- **ìµœì¢… ê³„ì¢Œ ì”ê³ **: {final_balance:,.0f}ì›")
    else:
        lines.append("- **ë‹¹ì¼ ì‹¤í˜„ ì†ìµ**: ìš”ì•½ ë°ì´í„° ì—†ìŒ")
        lines.append("- **ìµœì¢… ê³„ì¢Œ ì”ê³ **: ìš”ì•½ ë°ì´í„° ì—†ìŒ")

    lines.append("")
    return "\n".join(lines)


def generate_daily_report():
    """
    ì¼ì¼ íˆ¬ì ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì˜¤ëŠ˜ ë‚ ì§œì˜ ë¡œê·¸ íŒŒì¼ê³¼ ìš”ì•½ íŒŒì¼ì„ ì½ì–´ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
    """
    logger.info("ì¼ì¼ íˆ¬ì ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    setup_reporter()

    now = datetime.now()
    date_str_for_report = now.strftime("%Y-%m-%d")
    date_str_for_log = now.strftime("%Y%m%d")

    report_file_path = REPORT_DIR / REPORT_FILE_FORMAT.format(date_str_for_report)

    try:
        buy_events, sell_events, pnl_events = parse_log_file(date_str_for_log)
        summary_data = parse_summary_file(date_str_for_log)

        report_content = generate_report_content(
            date_str_for_report, buy_events, sell_events, pnl_events, summary_data
        )

        with open(report_file_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        logger.info(f"ì¼ì¼ íˆ¬ì ê²°ê³¼ ë¦¬í¬íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file_path}")

    except Exception as e:
        logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    generate_daily_report()
